# Ensemble trainer #

multi_gpu_train.py
A multi gpu trainer. titan_baseline.pbs uses this script with 1 GPU
for the baseline. xsede can use this to obtain parallel training. 

TODO
